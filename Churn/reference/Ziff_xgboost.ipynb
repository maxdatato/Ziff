{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.9</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0    KS             128       415  382-4657         no        yes   \n",
       "1    OH             107       415  371-7191         no        yes   \n",
       "2    NJ             137       415  358-1921         no         no   \n",
       "3    OH              84       408  375-9999        yes         no   \n",
       "4    OK              75       415  330-6626        yes         no   \n",
       "\n",
       "   VMail Message  Day Mins  Day Calls Day Charge   ...   Eve Calls Eve Charge  \\\n",
       "0             25     265.1        110          0   ...          99      16.78   \n",
       "1             26     161.6        123          0   ...         103      16.62   \n",
       "2              0     243.4        114          0   ...         110      10.30   \n",
       "3              0     299.4         71       50.9   ...          88       5.26   \n",
       "4              0     166.7        113      28.34   ...         122      12.61   \n",
       "\n",
       "   Night Mins  Night Calls  Night Charge Intl Mins  Intl Calls Intl Charge  \\\n",
       "0       244.7           91         11.01      10.0           3         2.7   \n",
       "1       254.4          103         11.45      13.7           3         3.7   \n",
       "2       162.6          104          7.32      12.2           5        3.29   \n",
       "3       196.9           89          8.86       6.6           7        1.78   \n",
       "4       186.9          121          8.41      10.1           3        2.73   \n",
       "\n",
       "  CustServ Calls  Churn?  \n",
       "0              1  False.  \n",
       "1              1  False.  \n",
       "2              0  False.  \n",
       "3              2  False.  \n",
       "4              3  False.  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "df = pd.read_csv('churn.csv',index_col=0)\n",
    "df =df.replace('?','0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['State', 'Account Length', 'Area Code', 'Phone', 'Int'l Plan',\n",
       "       'VMail Plan', 'VMail Message', 'Day Mins', 'Day Calls', 'Day Charge',\n",
       "       'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls',\n",
       "       'Night Charge', 'Intl Mins', 'Intl Calls', 'Intl Charge',\n",
       "       'CustServ Calls', 'Churn?'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 483 instances for churn class and 2850 instances for not-churn classes.\n",
      "Ratio of churn class over all instances: 0.14\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Get the Labels as integers\n",
    "y = df.iloc[:, 20].values\n",
    "labelencoder_y = LabelEncoder()\n",
    "# y = labelencoder_y.fit_transform(y)\n",
    "df['Churn'] = (df['Churn?'] == 'True.')\n",
    "y = df['Churn'].as_matrix().astype(np.int)\n",
    "print('There are {} instances for churn class and {} instances for not-churn classes.'.format(y.sum(), y.shape[0] - y.sum()))\n",
    "print('Ratio of churn class over all instances: {:.2f}'.format(float(y.sum()) / y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>107</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>137</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>84</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.9</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>223.4</td>\n",
       "      <td>98</td>\n",
       "      <td>37.98</td>\n",
       "      <td>220.6</td>\n",
       "      <td>101</td>\n",
       "      <td>18.75</td>\n",
       "      <td>203.9</td>\n",
       "      <td>118</td>\n",
       "      <td>9.18</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>121</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>218.2</td>\n",
       "      <td>88</td>\n",
       "      <td>37.09</td>\n",
       "      <td>348.5</td>\n",
       "      <td>108</td>\n",
       "      <td>29.62</td>\n",
       "      <td>212.6</td>\n",
       "      <td>118</td>\n",
       "      <td>9.57</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>147</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>79</td>\n",
       "      <td>26.69</td>\n",
       "      <td>103.1</td>\n",
       "      <td>94</td>\n",
       "      <td>8.76</td>\n",
       "      <td>211.8</td>\n",
       "      <td>96</td>\n",
       "      <td>9.53</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>117</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>184.5</td>\n",
       "      <td>97</td>\n",
       "      <td>31.37</td>\n",
       "      <td>351.6</td>\n",
       "      <td>80</td>\n",
       "      <td>29.89</td>\n",
       "      <td>215.8</td>\n",
       "      <td>90</td>\n",
       "      <td>9.71</td>\n",
       "      <td>8.7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49</td>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "      <td>258.6</td>\n",
       "      <td>84</td>\n",
       "      <td>43.96</td>\n",
       "      <td>222.0</td>\n",
       "      <td>111</td>\n",
       "      <td>18.87</td>\n",
       "      <td>326.4</td>\n",
       "      <td>97</td>\n",
       "      <td>14.69</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>129.1</td>\n",
       "      <td>137</td>\n",
       "      <td>21.95</td>\n",
       "      <td>228.5</td>\n",
       "      <td>83</td>\n",
       "      <td>19.42</td>\n",
       "      <td>208.8</td>\n",
       "      <td>111</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6</td>\n",
       "      <td>3.43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>187.7</td>\n",
       "      <td>127</td>\n",
       "      <td>31.91</td>\n",
       "      <td>163.4</td>\n",
       "      <td>148</td>\n",
       "      <td>13.89</td>\n",
       "      <td>196.0</td>\n",
       "      <td>94</td>\n",
       "      <td>8.82</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>168</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>128.8</td>\n",
       "      <td>96</td>\n",
       "      <td>21.9</td>\n",
       "      <td>104.9</td>\n",
       "      <td>71</td>\n",
       "      <td>8.92</td>\n",
       "      <td>141.1</td>\n",
       "      <td>128</td>\n",
       "      <td>6.35</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>156.6</td>\n",
       "      <td>88</td>\n",
       "      <td>26.62</td>\n",
       "      <td>247.6</td>\n",
       "      <td>75</td>\n",
       "      <td>21.05</td>\n",
       "      <td>192.3</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>5</td>\n",
       "      <td>3.32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>120.7</td>\n",
       "      <td>70</td>\n",
       "      <td>20.52</td>\n",
       "      <td>307.2</td>\n",
       "      <td>76</td>\n",
       "      <td>26.11</td>\n",
       "      <td>203.0</td>\n",
       "      <td>99</td>\n",
       "      <td>9.14</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34</td>\n",
       "      <td>161</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>332.9</td>\n",
       "      <td>67</td>\n",
       "      <td>56.59</td>\n",
       "      <td>317.8</td>\n",
       "      <td>97</td>\n",
       "      <td>27.01</td>\n",
       "      <td>160.6</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "      <td>196.4</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>280.9</td>\n",
       "      <td>90</td>\n",
       "      <td>23.88</td>\n",
       "      <td>89.3</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>4</td>\n",
       "      <td>3.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46</td>\n",
       "      <td>93</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>190.7</td>\n",
       "      <td>114</td>\n",
       "      <td>32.42</td>\n",
       "      <td>218.2</td>\n",
       "      <td>111</td>\n",
       "      <td>18.55</td>\n",
       "      <td>129.6</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>45</td>\n",
       "      <td>76</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "      <td>189.7</td>\n",
       "      <td>66</td>\n",
       "      <td>32.25</td>\n",
       "      <td>212.8</td>\n",
       "      <td>65</td>\n",
       "      <td>18.09</td>\n",
       "      <td>165.7</td>\n",
       "      <td>108</td>\n",
       "      <td>7.46</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>43</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>224.4</td>\n",
       "      <td>90</td>\n",
       "      <td>38.15</td>\n",
       "      <td>159.5</td>\n",
       "      <td>88</td>\n",
       "      <td>13.56</td>\n",
       "      <td>192.8</td>\n",
       "      <td>74</td>\n",
       "      <td>8.68</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>147</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>155.1</td>\n",
       "      <td>117</td>\n",
       "      <td>26.37</td>\n",
       "      <td>239.7</td>\n",
       "      <td>0</td>\n",
       "      <td>20.37</td>\n",
       "      <td>208.8</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>4</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>62.4</td>\n",
       "      <td>89</td>\n",
       "      <td>10.61</td>\n",
       "      <td>169.9</td>\n",
       "      <td>121</td>\n",
       "      <td>14.44</td>\n",
       "      <td>209.6</td>\n",
       "      <td>64</td>\n",
       "      <td>9.43</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>112</td>\n",
       "      <td>31.11</td>\n",
       "      <td>72.9</td>\n",
       "      <td>99</td>\n",
       "      <td>6.20</td>\n",
       "      <td>181.8</td>\n",
       "      <td>78</td>\n",
       "      <td>8.18</td>\n",
       "      <td>9.5</td>\n",
       "      <td>19</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>111</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>110.4</td>\n",
       "      <td>103</td>\n",
       "      <td>18.77</td>\n",
       "      <td>137.3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.67</td>\n",
       "      <td>189.6</td>\n",
       "      <td>105</td>\n",
       "      <td>8.53</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>81.1</td>\n",
       "      <td>86</td>\n",
       "      <td>13.79</td>\n",
       "      <td>245.2</td>\n",
       "      <td>72</td>\n",
       "      <td>20.84</td>\n",
       "      <td>237.0</td>\n",
       "      <td>115</td>\n",
       "      <td>10.67</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>29</td>\n",
       "      <td>174</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>124.3</td>\n",
       "      <td>76</td>\n",
       "      <td>21.13</td>\n",
       "      <td>277.1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.55</td>\n",
       "      <td>250.7</td>\n",
       "      <td>115</td>\n",
       "      <td>11.28</td>\n",
       "      <td>15.5</td>\n",
       "      <td>5</td>\n",
       "      <td>4.19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>213.0</td>\n",
       "      <td>115</td>\n",
       "      <td>36.21</td>\n",
       "      <td>191.1</td>\n",
       "      <td>112</td>\n",
       "      <td>16.24</td>\n",
       "      <td>182.7</td>\n",
       "      <td>115</td>\n",
       "      <td>8.22</td>\n",
       "      <td>9.5</td>\n",
       "      <td>3</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>134.3</td>\n",
       "      <td>73</td>\n",
       "      <td>22.83</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>13.22</td>\n",
       "      <td>102.1</td>\n",
       "      <td>68</td>\n",
       "      <td>4.59</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>109</td>\n",
       "      <td>32.3</td>\n",
       "      <td>258.2</td>\n",
       "      <td>84</td>\n",
       "      <td>21.95</td>\n",
       "      <td>181.5</td>\n",
       "      <td>102</td>\n",
       "      <td>8.17</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>119.3</td>\n",
       "      <td>117</td>\n",
       "      <td>20.28</td>\n",
       "      <td>215.1</td>\n",
       "      <td>109</td>\n",
       "      <td>18.28</td>\n",
       "      <td>178.7</td>\n",
       "      <td>90</td>\n",
       "      <td>8.04</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>31</td>\n",
       "      <td>138</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>241.8</td>\n",
       "      <td>93</td>\n",
       "      <td>41.11</td>\n",
       "      <td>170.5</td>\n",
       "      <td>0</td>\n",
       "      <td>14.49</td>\n",
       "      <td>295.3</td>\n",
       "      <td>104</td>\n",
       "      <td>13.29</td>\n",
       "      <td>11.8</td>\n",
       "      <td>7</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>23</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "      <td>224.9</td>\n",
       "      <td>97</td>\n",
       "      <td>38.23</td>\n",
       "      <td>188.2</td>\n",
       "      <td>84</td>\n",
       "      <td>16.00</td>\n",
       "      <td>254.6</td>\n",
       "      <td>61</td>\n",
       "      <td>11.46</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>32</td>\n",
       "      <td>147</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>248.6</td>\n",
       "      <td>83</td>\n",
       "      <td>42.26</td>\n",
       "      <td>148.9</td>\n",
       "      <td>85</td>\n",
       "      <td>12.66</td>\n",
       "      <td>172.5</td>\n",
       "      <td>109</td>\n",
       "      <td>7.76</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>33</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>203.4</td>\n",
       "      <td>146</td>\n",
       "      <td>34.58</td>\n",
       "      <td>226.7</td>\n",
       "      <td>117</td>\n",
       "      <td>19.27</td>\n",
       "      <td>152.4</td>\n",
       "      <td>105</td>\n",
       "      <td>6.86</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>11</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>235.8</td>\n",
       "      <td>109</td>\n",
       "      <td>40.09</td>\n",
       "      <td>157.2</td>\n",
       "      <td>94</td>\n",
       "      <td>13.36</td>\n",
       "      <td>188.2</td>\n",
       "      <td>99</td>\n",
       "      <td>8.47</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>23</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>157.1</td>\n",
       "      <td>90</td>\n",
       "      <td>26.71</td>\n",
       "      <td>223.3</td>\n",
       "      <td>72</td>\n",
       "      <td>18.98</td>\n",
       "      <td>181.4</td>\n",
       "      <td>111</td>\n",
       "      <td>8.16</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>300.3</td>\n",
       "      <td>109</td>\n",
       "      <td>51.05</td>\n",
       "      <td>181.0</td>\n",
       "      <td>100</td>\n",
       "      <td>15.39</td>\n",
       "      <td>270.1</td>\n",
       "      <td>73</td>\n",
       "      <td>12.15</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>34</td>\n",
       "      <td>144</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>117</td>\n",
       "      <td>10.47</td>\n",
       "      <td>77.1</td>\n",
       "      <td>85</td>\n",
       "      <td>6.55</td>\n",
       "      <td>173.0</td>\n",
       "      <td>99</td>\n",
       "      <td>7.79</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7</td>\n",
       "      <td>2.21</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>214.1</td>\n",
       "      <td>72</td>\n",
       "      <td>36.4</td>\n",
       "      <td>164.4</td>\n",
       "      <td>104</td>\n",
       "      <td>13.97</td>\n",
       "      <td>177.5</td>\n",
       "      <td>113</td>\n",
       "      <td>7.99</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>170.2</td>\n",
       "      <td>98</td>\n",
       "      <td>28.93</td>\n",
       "      <td>155.2</td>\n",
       "      <td>102</td>\n",
       "      <td>13.19</td>\n",
       "      <td>228.6</td>\n",
       "      <td>76</td>\n",
       "      <td>10.29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>201.1</td>\n",
       "      <td>99</td>\n",
       "      <td>34.19</td>\n",
       "      <td>303.5</td>\n",
       "      <td>74</td>\n",
       "      <td>25.80</td>\n",
       "      <td>224.0</td>\n",
       "      <td>119</td>\n",
       "      <td>10.08</td>\n",
       "      <td>13.2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>37</td>\n",
       "      <td>116</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>215.4</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>204.8</td>\n",
       "      <td>79</td>\n",
       "      <td>17.41</td>\n",
       "      <td>278.5</td>\n",
       "      <td>109</td>\n",
       "      <td>12.53</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>165.6</td>\n",
       "      <td>123</td>\n",
       "      <td>28.15</td>\n",
       "      <td>136.1</td>\n",
       "      <td>95</td>\n",
       "      <td>11.57</td>\n",
       "      <td>175.7</td>\n",
       "      <td>90</td>\n",
       "      <td>7.91</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>249.5</td>\n",
       "      <td>101</td>\n",
       "      <td>42.42</td>\n",
       "      <td>259.7</td>\n",
       "      <td>98</td>\n",
       "      <td>22.07</td>\n",
       "      <td>222.7</td>\n",
       "      <td>68</td>\n",
       "      <td>10.02</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>43</td>\n",
       "      <td>106</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>210.6</td>\n",
       "      <td>96</td>\n",
       "      <td>35.8</td>\n",
       "      <td>249.2</td>\n",
       "      <td>85</td>\n",
       "      <td>21.18</td>\n",
       "      <td>191.4</td>\n",
       "      <td>88</td>\n",
       "      <td>8.61</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>46</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>179.3</td>\n",
       "      <td>104</td>\n",
       "      <td>30.48</td>\n",
       "      <td>225.9</td>\n",
       "      <td>86</td>\n",
       "      <td>19.20</td>\n",
       "      <td>323.0</td>\n",
       "      <td>78</td>\n",
       "      <td>14.54</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>157.9</td>\n",
       "      <td>105</td>\n",
       "      <td>26.84</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.18</td>\n",
       "      <td>189.6</td>\n",
       "      <td>84</td>\n",
       "      <td>8.53</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>49</td>\n",
       "      <td>111</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>214.3</td>\n",
       "      <td>118</td>\n",
       "      <td>36.43</td>\n",
       "      <td>208.5</td>\n",
       "      <td>0</td>\n",
       "      <td>17.72</td>\n",
       "      <td>182.4</td>\n",
       "      <td>98</td>\n",
       "      <td>8.21</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>17</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "      <td>154.1</td>\n",
       "      <td>104</td>\n",
       "      <td>26.2</td>\n",
       "      <td>123.4</td>\n",
       "      <td>84</td>\n",
       "      <td>10.49</td>\n",
       "      <td>202.1</td>\n",
       "      <td>57</td>\n",
       "      <td>9.09</td>\n",
       "      <td>10.9</td>\n",
       "      <td>9</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>31</td>\n",
       "      <td>128</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>237.9</td>\n",
       "      <td>125</td>\n",
       "      <td>40.44</td>\n",
       "      <td>247.6</td>\n",
       "      <td>93</td>\n",
       "      <td>21.05</td>\n",
       "      <td>208.9</td>\n",
       "      <td>68</td>\n",
       "      <td>9.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>4</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>7</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>143.9</td>\n",
       "      <td>61</td>\n",
       "      <td>24.46</td>\n",
       "      <td>194.9</td>\n",
       "      <td>105</td>\n",
       "      <td>16.57</td>\n",
       "      <td>109.6</td>\n",
       "      <td>94</td>\n",
       "      <td>4.93</td>\n",
       "      <td>11.1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>18</td>\n",
       "      <td>155</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>203.4</td>\n",
       "      <td>100</td>\n",
       "      <td>34.58</td>\n",
       "      <td>190.9</td>\n",
       "      <td>104</td>\n",
       "      <td>16.23</td>\n",
       "      <td>196.0</td>\n",
       "      <td>119</td>\n",
       "      <td>8.82</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>124.3</td>\n",
       "      <td>100</td>\n",
       "      <td>21.13</td>\n",
       "      <td>173.0</td>\n",
       "      <td>107</td>\n",
       "      <td>14.71</td>\n",
       "      <td>253.2</td>\n",
       "      <td>62</td>\n",
       "      <td>11.39</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>21</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>252.9</td>\n",
       "      <td>93</td>\n",
       "      <td>42.99</td>\n",
       "      <td>178.4</td>\n",
       "      <td>112</td>\n",
       "      <td>15.16</td>\n",
       "      <td>263.9</td>\n",
       "      <td>105</td>\n",
       "      <td>11.88</td>\n",
       "      <td>9.5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>179.1</td>\n",
       "      <td>71</td>\n",
       "      <td>30.45</td>\n",
       "      <td>190.6</td>\n",
       "      <td>81</td>\n",
       "      <td>16.20</td>\n",
       "      <td>127.7</td>\n",
       "      <td>91</td>\n",
       "      <td>5.75</td>\n",
       "      <td>10.6</td>\n",
       "      <td>7</td>\n",
       "      <td>2.86</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>278.4</td>\n",
       "      <td>106</td>\n",
       "      <td>47.33</td>\n",
       "      <td>81.0</td>\n",
       "      <td>113</td>\n",
       "      <td>6.89</td>\n",
       "      <td>163.2</td>\n",
       "      <td>137</td>\n",
       "      <td>7.34</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>26</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>160.1</td>\n",
       "      <td>110</td>\n",
       "      <td>27.22</td>\n",
       "      <td>213.3</td>\n",
       "      <td>72</td>\n",
       "      <td>18.13</td>\n",
       "      <td>174.1</td>\n",
       "      <td>72</td>\n",
       "      <td>7.83</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>198.2</td>\n",
       "      <td>87</td>\n",
       "      <td>33.69</td>\n",
       "      <td>207.3</td>\n",
       "      <td>76</td>\n",
       "      <td>17.62</td>\n",
       "      <td>190.9</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>25</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>212.1</td>\n",
       "      <td>131</td>\n",
       "      <td>36.06</td>\n",
       "      <td>209.4</td>\n",
       "      <td>104</td>\n",
       "      <td>17.80</td>\n",
       "      <td>167.2</td>\n",
       "      <td>96</td>\n",
       "      <td>7.52</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>251.8</td>\n",
       "      <td>72</td>\n",
       "      <td>42.81</td>\n",
       "      <td>205.7</td>\n",
       "      <td>126</td>\n",
       "      <td>17.48</td>\n",
       "      <td>275.2</td>\n",
       "      <td>109</td>\n",
       "      <td>12.38</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    State  Account Length  Int'l Plan  VMail Plan  VMail Message  Day Mins  \\\n",
       "0      16             128       False        True             25     265.1   \n",
       "1      35             107       False        True             26     161.6   \n",
       "2      31             137       False       False              0     243.4   \n",
       "3      35              84        True       False              0     299.4   \n",
       "4      36              75        True       False              0     166.7   \n",
       "5       1             118        True       False              0     223.4   \n",
       "6      19             121       False        True             24     218.2   \n",
       "7      24             147        True       False              0     157.0   \n",
       "8      18             117       False       False              0     184.5   \n",
       "9      49             141        True        True             37     258.6   \n",
       "10     15              65       False       False              0     129.1   \n",
       "11     39              74       False       False              0     187.7   \n",
       "12     12             168       False       False              0     128.8   \n",
       "13     26              95       False       False              0     156.6   \n",
       "14     12              62       False       False              0     120.7   \n",
       "15     34             161       False       False              0     332.9   \n",
       "16     13              85       False        True             27     196.4   \n",
       "17     46              93       False       False              0     190.7   \n",
       "18     45              76       False        True             33     189.7   \n",
       "19     43              73       False       False              0     224.4   \n",
       "20      9             147       False       False              0     155.1   \n",
       "21      5              77       False       False              0      62.4   \n",
       "22      3             130       False       False              0     183.0   \n",
       "23     40             111       False       False              0     110.4   \n",
       "24     45             132       False       False              0      81.1   \n",
       "25     29             174       False       False              0     124.3   \n",
       "26     50              57       False        True             39     213.0   \n",
       "27     26              54       False       False              0     134.3   \n",
       "28     24              20       False       False              0     190.0   \n",
       "29     11              49       False       False              0     119.3   \n",
       "..    ...             ...         ...         ...            ...       ...   \n",
       "70     31             138       False       False              0     241.8   \n",
       "71     23             162       False        True             46     224.9   \n",
       "72     32             147       False       False              0     248.6   \n",
       "73     33              90       False       False              0     203.4   \n",
       "74     11              85       False       False              0     235.8   \n",
       "75     23              50       False       False              0     157.1   \n",
       "76      7              82       False       False              0     300.3   \n",
       "77     34             144       False       False              0      61.6   \n",
       "78     23              46       False       False              0     214.1   \n",
       "79     20              70       False       False              0     170.2   \n",
       "80     49             144       False       False              0     201.1   \n",
       "81     37             116        True       False              0     215.4   \n",
       "82      5              55       False        True             25     165.6   \n",
       "83     10              70       False        True             24     249.5   \n",
       "84     43             106       False       False              0     210.6   \n",
       "85     46             128       False       False             29     179.3   \n",
       "86     15              94       False       False              0     157.9   \n",
       "87     49             111       False       False              0     214.3   \n",
       "88     17              74       False        True             35     154.1   \n",
       "89     31             128       False       False              0     237.9   \n",
       "90      7              82       False       False              0     143.9   \n",
       "91     18             155       False       False              0     203.4   \n",
       "92      2              80       False       False              0     124.3   \n",
       "93     21              78       False       False              0     252.9   \n",
       "94      3              90       False       False              0     179.1   \n",
       "95      0             104       False       False              0     278.4   \n",
       "96     26              73       False       False              0     160.1   \n",
       "97      3              99       False       False              0     198.2   \n",
       "98     25             120       False       False              0     212.1   \n",
       "99     13              77       False       False              0     251.8   \n",
       "\n",
       "    Day Calls Day Charge Eve Mins Eve Calls  Eve Charge  Night Mins  \\\n",
       "0         110          0    197.4        99       16.78       244.7   \n",
       "1         123          0    195.5       103       16.62       254.4   \n",
       "2         114          0    121.2       110       10.30       162.6   \n",
       "3          71       50.9     61.9        88        5.26       196.9   \n",
       "4         113      28.34    148.3       122       12.61       186.9   \n",
       "5          98      37.98    220.6       101       18.75       203.9   \n",
       "6          88      37.09    348.5       108       29.62       212.6   \n",
       "7          79      26.69    103.1        94        8.76       211.8   \n",
       "8          97      31.37    351.6        80       29.89       215.8   \n",
       "9          84      43.96    222.0       111       18.87       326.4   \n",
       "10        137      21.95    228.5        83       19.42       208.8   \n",
       "11        127      31.91    163.4       148       13.89       196.0   \n",
       "12         96       21.9    104.9        71        8.92       141.1   \n",
       "13         88      26.62    247.6        75       21.05       192.3   \n",
       "14         70      20.52    307.2        76       26.11       203.0   \n",
       "15         67      56.59    317.8        97       27.01       160.6   \n",
       "16        139          0    280.9        90       23.88        89.3   \n",
       "17        114      32.42    218.2       111       18.55       129.6   \n",
       "18         66      32.25    212.8        65       18.09       165.7   \n",
       "19         90      38.15    159.5        88       13.56       192.8   \n",
       "20        117      26.37    239.7         0       20.37       208.8   \n",
       "21         89      10.61    169.9       121       14.44       209.6   \n",
       "22        112      31.11     72.9        99        6.20       181.8   \n",
       "23        103      18.77    137.3         0       11.67       189.6   \n",
       "24         86      13.79    245.2        72       20.84       237.0   \n",
       "25         76      21.13    277.1         0       23.55       250.7   \n",
       "26        115      36.21    191.1       112       16.24       182.7   \n",
       "27         73      22.83        0       100       13.22       102.1   \n",
       "28        109       32.3    258.2        84       21.95       181.5   \n",
       "29        117      20.28    215.1       109       18.28       178.7   \n",
       "..        ...        ...      ...       ...         ...         ...   \n",
       "70         93      41.11    170.5         0       14.49       295.3   \n",
       "71         97      38.23    188.2        84       16.00       254.6   \n",
       "72         83      42.26    148.9        85       12.66       172.5   \n",
       "73        146      34.58    226.7       117       19.27       152.4   \n",
       "74        109      40.09    157.2        94       13.36       188.2   \n",
       "75         90      26.71    223.3        72       18.98       181.4   \n",
       "76        109      51.05    181.0       100       15.39       270.1   \n",
       "77        117      10.47     77.1        85        6.55       173.0   \n",
       "78         72       36.4    164.4       104       13.97       177.5   \n",
       "79         98      28.93    155.2       102       13.19       228.6   \n",
       "80         99      34.19    303.5        74       25.80       224.0   \n",
       "81        104          0    204.8        79       17.41       278.5   \n",
       "82        123      28.15    136.1        95       11.57       175.7   \n",
       "83        101      42.42    259.7        98       22.07       222.7   \n",
       "84         96       35.8    249.2        85       21.18       191.4   \n",
       "85        104      30.48    225.9        86       19.20       323.0   \n",
       "86        105      26.84    155.0         0       13.18       189.6   \n",
       "87        118      36.43    208.5         0       17.72       182.4   \n",
       "88        104       26.2    123.4        84       10.49       202.1   \n",
       "89        125      40.44    247.6        93       21.05       208.9   \n",
       "90         61      24.46    194.9       105       16.57       109.6   \n",
       "91        100      34.58    190.9       104       16.23       196.0   \n",
       "92        100      21.13    173.0       107       14.71       253.2   \n",
       "93         93      42.99    178.4       112       15.16       263.9   \n",
       "94         71      30.45    190.6        81       16.20       127.7   \n",
       "95        106      47.33     81.0       113        6.89       163.2   \n",
       "96        110      27.22    213.3        72       18.13       174.1   \n",
       "97         87      33.69    207.3        76       17.62       190.9   \n",
       "98        131      36.06    209.4       104       17.80       167.2   \n",
       "99         72      42.81    205.7       126       17.48       275.2   \n",
       "\n",
       "    Night Calls Night Charge  Intl Mins Intl Calls Intl Charge  CustServ Calls  \n",
       "0            91        11.01       10.0          3         2.7               1  \n",
       "1           103        11.45       13.7          3         3.7               1  \n",
       "2           104         7.32       12.2          5        3.29               0  \n",
       "3            89         8.86        6.6          7        1.78               2  \n",
       "4           121         8.41       10.1          3        2.73               3  \n",
       "5           118         9.18        6.3          6         1.7               0  \n",
       "6           118         9.57        7.5          7        2.03               3  \n",
       "7            96         9.53        7.1          0        1.92               0  \n",
       "8            90         9.71        8.7          4           0               1  \n",
       "9            97        14.69       11.2          5        3.02               0  \n",
       "10          111          9.4       12.7          6        3.43               4  \n",
       "11           94         8.82        9.1          0        2.46               0  \n",
       "12          128         6.35       11.2          0        3.02               1  \n",
       "13          115            0       12.3          5        3.32               3  \n",
       "14           99         9.14       13.1          0        3.54               4  \n",
       "15          128            0        5.4          9        1.46               4  \n",
       "16           75            0       13.8          4        3.73               1  \n",
       "17          121            0        8.1          3        2.19               3  \n",
       "18          108         7.46       10.0          0         2.7               1  \n",
       "19           74         8.68       13.0          0        3.51               1  \n",
       "20          133            0       10.6          4        2.86               0  \n",
       "21           64         9.43        5.7          0        1.54               5  \n",
       "22           78         8.18        9.5         19        2.57               0  \n",
       "23          105         8.53        7.7          6        2.08               2  \n",
       "24          115        10.67       10.3          0           0               0  \n",
       "25          115        11.28       15.5          5        4.19               3  \n",
       "26          115         8.22        9.5          3        2.57               0  \n",
       "27           68         4.59       14.7          0        3.97               3  \n",
       "28          102         8.17        6.3          6         1.7               0  \n",
       "29           90         8.04       11.1          1         3.0               1  \n",
       "..          ...          ...        ...        ...         ...             ...  \n",
       "70          104        13.29       11.8          7        3.19               3  \n",
       "71           61        11.46       12.1          0        3.27               0  \n",
       "72          109         7.76        8.0          4        2.16               3  \n",
       "73          105         6.86        7.3          0        1.97               1  \n",
       "74           99         8.47       12.0          3           0               0  \n",
       "75          111         8.16        6.1          2        1.65               1  \n",
       "76           73        12.15       11.7          4           0               0  \n",
       "77           99         7.79        8.2          7        2.21               4  \n",
       "78          113         7.99        8.2          0        2.21               2  \n",
       "79           76        10.29       15.0          2        4.05               1  \n",
       "80          119        10.08       13.2          2        3.56               1  \n",
       "81          109        12.53       12.6          5         3.4               3  \n",
       "82           90         7.91       11.0          0        2.97               3  \n",
       "83           68        10.02        9.8          0        2.65               1  \n",
       "84           88         8.61       12.4          1        3.35               2  \n",
       "85           78        14.54        8.6          7        2.32               0  \n",
       "86           84         8.53        8.0          5        2.16               4  \n",
       "87           98         8.21       12.0          2        3.24               1  \n",
       "88           57         9.09       10.9          9        2.94               2  \n",
       "89           68          9.4       13.9          4        3.75               1  \n",
       "90           94         4.93       11.1          2         3.0               1  \n",
       "91          119         8.82        8.9          4         2.4               0  \n",
       "92           62        11.39        7.9          9        2.13               1  \n",
       "93          105        11.88        9.5          7        2.57               3  \n",
       "94           91         5.75       10.6          7        2.86               3  \n",
       "95          137         7.34        9.8          5        2.65               1  \n",
       "96           72         7.83       13.0          4        3.51               0  \n",
       "97          113            0        8.7          3        2.35               4  \n",
       "98           96         7.52        5.3          5        1.43               1  \n",
       "99          109        12.38        9.8          7        2.65               2  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "df2 = df\n",
    "# State is string and we want discre integer values\n",
    "labelencoder = LabelEncoder()\n",
    "df2['State'] = labelencoder.fit_transform(df2['State'])\n",
    "\n",
    "# Drop the redundant columns from dataframe\n",
    "df2.drop(['Area Code','Phone','Churn','Churn?'], axis=1, inplace=True)\n",
    "\n",
    "# Get the features as integers similar to what we did for labels(targets)\n",
    "df2[[\"Int'l Plan\",\"VMail Plan\"]] = df2[[\"Int'l Plan\",\"VMail Plan\"]] == 'yes'\n",
    "\n",
    "df2.head(100)\n",
    "\n",
    "# labelencoder_X_1 = LabelEncoder()\n",
    "# X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "# labelencoder_X_2 = LabelEncoder()\n",
    "# X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "# onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "# X = onehotencoder.fit_transform(X).toarray()\n",
    "# X = X[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  16.  ,  128.  ,    0.  , ...,    3.  ,    2.7 ,    1.  ],\n",
       "       [  35.  ,  107.  ,    0.  , ...,    3.  ,    3.7 ,    1.  ],\n",
       "       [  31.  ,  137.  ,    0.  , ...,    5.  ,    3.29,    0.  ],\n",
       "       ..., \n",
       "       [  39.  ,   28.  ,    0.  , ...,    6.  ,    3.81,    2.  ],\n",
       "       [   6.  ,  184.  ,    1.  , ...,   10.  ,    1.35,    2.  ],\n",
       "       [  42.  ,   74.  ,    0.  , ...,    0.  ,    3.7 ,    0.  ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.as_matrix().astype(np.float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "# sc_y = StandardScaler()\n",
    "# y = sc_y.fit_transform(y)\n",
    "\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "# y_train = sc_X.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6786493 ,  0.67648946, -0.30047395, ..., -0.21073146,\n",
       "         0.20508928, -0.42793202],\n",
       "       [ 0.6031696 ,  0.14906505, -0.30047395, ..., -0.21073146,\n",
       "         1.10430073, -0.42793202],\n",
       "       [ 0.33331299,  0.9025285 , -0.30047395, ...,  0.48571669,\n",
       "         0.73562404, -1.1882185 ],\n",
       "       ..., \n",
       "       [ 0.87302621, -1.83505538, -0.30047395, ...,  0.83394077,\n",
       "         1.20321399,  0.33235445],\n",
       "       [-1.35329082,  2.08295458,  3.32807556, ...,  2.22683707,\n",
       "        -1.00884619,  0.33235445],\n",
       "       [ 1.07541867, -0.67974475, -0.30047395, ..., -1.25540369,\n",
       "         1.10430073, -1.1882185 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_cv(X, y, clf_class, shuffle=True, n_folds=10, **kwargs):\n",
    "    stratified_k_fold = cross_validation.StratifiedKFold(y, n_folds=n_folds, shuffle=shuffle)\n",
    "    y_pred = y.copy()\n",
    "    for ii, jj in stratified_k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[jj] = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump Classifier:               0.86\n",
      "Passive Aggressive Classifier: 0.81\n",
      "Ridge Classifier:              0.86\n",
      "Logistic Regression:           0.86\n",
      "K Nearest Neighbor Classifier: 0.88\n",
      "Support vector machine(SVM):   0.91\n",
      "Decision Tree Classifier:      0.90\n",
      "Random Forest Classifier:      0.93\n",
      "Gradient Boosting Classifier:  0.94\n",
      "XGBoost:                       0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print('Dump Classifier:               {:.2f}'.format(accuracy_score(y, [0 for ii in y.tolist()])))\n",
    "print('Passive Aggressive Classifier: {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, linear_model.PassiveAggressiveClassifier))))\n",
    "print('Ridge Classifier:              {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, linear_model.RidgeClassifier))))\n",
    "print('Logistic Regression:           {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, linear_model.LogisticRegression))))\n",
    "print('K Nearest Neighbor Classifier: {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, neighbors.KNeighborsClassifier))))\n",
    "print('Support vector machine(SVM):   {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, svm.SVC))))\n",
    "print('Decision Tree Classifier:      {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, tree.DecisionTreeClassifier))))\n",
    "print('Random Forest Classifier:      {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, ensemble.RandomForestClassifier))))\n",
    "print('Gradient Boosting Classifier:  {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, ensemble.GradientBoostingClassifier))))\n",
    "print('XGBoost:                       {:.2f}'.format(accuracy_score(y, stratified_cv(X, y, XGBClassifier))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumb_conf_matrix = metrics.confusion_matrix(y, [0 for ii in y.tolist()]); # ignore the warning as they are all 0\n",
    "pass_agg_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, linear_model.PassiveAggressiveClassifier))\n",
    "ridge_clf_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, linear_model.RidgeClassifier))\n",
    "logistic_reg_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, linear_model.LogisticRegression))\n",
    "k_neighbors_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, neighbors.KNeighborsClassifier))\n",
    "svm_svc_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, svm.SVC))\n",
    "decision_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, tree.DecisionTreeClassifier))\n",
    "random_forest_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, ensemble.RandomForestClassifier))\n",
    "grad_ens_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, ensemble.GradientBoostingClassifier))\n",
    "XGB_ens_conf_matrix = metrics.confusion_matrix(y, stratified_cv(X, y, XGBClassifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dump Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92      2850\n",
      "          1       0.00      0.00      0.00       483\n",
      "\n",
      "avg / total       0.73      0.86      0.79      3333\n",
      "\n",
      "\n",
      "Passive Aggressive Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88      2850\n",
      "          1       0.30      0.31      0.30       483\n",
      "\n",
      "avg / total       0.80      0.79      0.80      3333\n",
      "\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      2850\n",
      "          1       0.88      0.67      0.76       483\n",
      "\n",
      "avg / total       0.94      0.94      0.94      3333\n",
      "\n",
      "\n",
      "Support vector machine(SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95      2850\n",
      "          1       0.85      0.46      0.60       483\n",
      "\n",
      "avg / total       0.91      0.91      0.90      3333\n",
      "\n",
      "\n",
      "Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96      2850\n",
      "          1       0.90      0.55      0.68       483\n",
      "\n",
      "avg / total       0.92      0.93      0.92      3333\n",
      "\n",
      "\n",
      "K Nearest Neighbor Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94      2850\n",
      "          1       0.74      0.34      0.47       483\n",
      "\n",
      "avg / total       0.87      0.89      0.87      3333\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.97      0.92      2850\n",
      "          1       0.54      0.19      0.29       483\n",
      "\n",
      "avg / total       0.83      0.86      0.83      3333\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Dump Classifier:\\n {}\\n'.format(metrics.classification_report(y, [0 for ii in y.tolist()]))); # ignore the warning as they are all 0\n",
    "print('Passive Aggressive Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, linear_model.PassiveAggressiveClassifier))))\n",
    "print('Logistic Regression:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, linear_model.LogisticRegression))))\n",
    "print('Support vector machine(SVM):\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, svm.SVC))))\n",
    "print('Random Forest Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, ensemble.RandomForestClassifier))))\n",
    "print('K Nearest Neighbor Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, neighbors.KNeighborsClassifier))))\n",
    "print('Gradient Boosting Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, ensemble.GradientBoostingClassifier))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+MAAALJCAYAAADfxPI0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh8EWYMQZzE0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb40adfa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbc = ensemble.GradientBoostingClassifier()\n",
    "gbc.fit(X, y)\n",
    "# Get Feature Importance from the classifier\n",
    "feature_importance = gbc.feature_importances_\n",
    "# Normalize The Features\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(16, 12))\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center', color='#7A68A6')\n",
    "plt.yticks(pos, np.asanyarray(df.columns.tolist())[sorted_idx])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.as_matrix().astype(np.float)\n",
    "polynomial_features = preprocessing.PolynomialFeatures()\n",
    "X = polynomial_features.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passive Aggressive Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.99      0.92      2850\n",
      "          1       0.41      0.05      0.09       483\n",
      "\n",
      "avg / total       0.79      0.85      0.80      3333\n",
      "\n",
      "\n",
      "Gradient Boosting Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      2850\n",
      "          1       0.91      0.72      0.80       483\n",
      "\n",
      "avg / total       0.95      0.95      0.95      3333\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector machine(SVM):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92      2850\n",
      "          1       0.00      0.00      0.00       483\n",
      "\n",
      "avg / total       0.73      0.86      0.79      3333\n",
      "\n",
      "\n",
      "Random Forest Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.97      2850\n",
      "          1       0.93      0.64      0.76       483\n",
      "\n",
      "avg / total       0.94      0.94      0.94      3333\n",
      "\n",
      "\n",
      "K Nearest Neighbor Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.97      0.93      2850\n",
      "          1       0.64      0.27      0.38       483\n",
      "\n",
      "avg / total       0.85      0.87      0.85      3333\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.97      0.94      2850\n",
      "          1       0.72      0.49      0.59       483\n",
      "\n",
      "avg / total       0.89      0.90      0.89      3333\n",
      "\n",
      "\n",
      "Dump Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92      2850\n",
      "          1       0.00      0.00      0.00       483\n",
      "\n",
      "avg / total       0.73      0.86      0.79      3333\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Passive Aggressive Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, linear_model.PassiveAggressiveClassifier))))\n",
    "print('Gradient Boosting Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, ensemble.GradientBoostingClassifier))))\n",
    "print('Support vector machine(SVM):\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, svm.SVC))))\n",
    "print('Random Forest Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, ensemble.RandomForestClassifier))))\n",
    "print('K Nearest Neighbor Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, neighbors.KNeighborsClassifier))))\n",
    "print('Logistic Regression:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, linear_model.LogisticRegression))))\n",
    "print('Dump Classifier:\\n {}\\n'.format(metrics.classification_report(y, [0 for ii in y.tolist()]))); # ignore the warning as they are all 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.as_matrix().astype(np.float)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "polynomial_features = preprocessing.PolynomialFeatures()\n",
    "X = polynomial_features.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Passive Aggressive Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, linear_model.PassiveAggressiveClassifier))))\n",
    "print('Gradient Boosting Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, ensemble.GradientBoostingClassifier))))\n",
    "print('Support vector machine(SVM):\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, svm.SVC))))\n",
    "print('Random Forest Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, ensemble.RandomForestClassifier))))\n",
    "print('K Nearest Neighbor Classifier:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, neighbors.KNeighborsClassifier))))\n",
    "print('Logistic Regression:\\n {}\\n'.format(metrics.classification_report(y, stratified_cv(X, y, linear_model.LogisticRegression))))\n",
    "print('Dump Classifier:\\n {}\\n'.format(metrics.classification_report(y, [0 for ii in y.tolist()]))); # ignore the warning as they are all 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b3c7d891813b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Making the Confusion Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Applying k-Fold Cross Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X, y = y, cv = 10)\n",
    "accuracies.mean()\n",
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
